# Prompt 13 ‚Äî LLM Log: Registro Institucional das A√ß√µes de Intelig√™ncia Artificial

Voc√™ vai construir o **registro simb√≥lico e audit√°vel de todas as a√ß√µes realizadas por modelos de linguagem (LLMs)**  
dentro do sistema MINICONTRATOS.

Esse m√≥dulo transforma qualquer infer√™ncia, sugest√£o, execu√ß√£o ou participa√ß√£o de IA em uma **LogLine com rastro, assinatura e consequ√™ncia**.

---

## üéØ Objetivo

- Registrar toda a√ß√£o da IA como um **ato institucional**
- Atribuir responsabilidade ao modelo usado
- Rastrear par√¢metros da infer√™ncia (modelo, temperatura, tokens, fallback)
- Permitir auditoria sem√¢ntica, reversibilidade e justi√ßa operativa

---

## üß± Exemplo de LogLine de IA

```json
{
  "who": "llm.gpt-4o",
  "did": "sugeriu_contrato",
  "this": "entrega turno 044",
  "when": "2025-05-21T14:33:00Z",
  "status": "valid",
  "confirmed_by": "ruleset.intent_payment.v1",
  "prompt": "prompt.minicontrato_sugestao_v4",
  "temperature": 0.4,
  "tokens": 1423,
  "fallback": false,
  "simulation": false,
  "model_fingerprint": "gpt-4o-20240501"
}
```

---

## ‚úÖ Campos obrigat√≥rios no LogLine da IA

| Campo             | Descri√ß√£o                                                        |
|------------------|------------------------------------------------------------------|
| `who`             | `llm.nome.versao` (ex: `llm.bitnet.b158`)                        |
| `prompt`          | Nome institucional do prompt usado (`prompt.ghost_revisor_v2`)  |
| `temperature`     | Temperatura usada na infer√™ncia                                 |
| `tokens`          | Total de tokens usados (input + output)                         |
| `fallback`        | Se foi acionado como plano B (`true/false`)                     |
| `simulation`      | Se a infer√™ncia foi feita em modo revers√≠vel                    |
| `confirmed_by`    | Pol√≠tica ou agente que aceitou o uso daquela resposta           |
| `model_fingerprint` | Identificador da vers√£o exata do modelo                       |

---

## üîÅ Fallback Institucional

Se o modelo principal falha (timeout, custo, baixa confian√ßa):

1. Gerar LogLine `did: falha_na_ia`
2. Acionar fallback (ex: Claude, DeepSeek)
3. Gerar LogLine `did: fallback_llm` com `fallback: true`
4. Registrar ambas as decis√µes

---

## üîç Auditoria e Consulta

- A√ß√µes da IA vis√≠veis na timeline `/logline`
- Painel de IA institucional com:
  - Hist√≥rico de uso por modelo
  - Respostas simuladas vs. reais
  - Confirmadores humanos ou regras
  - Detec√ß√£o de diverg√™ncia entre modelos

---

## üß† Padr√µes institucionais

- Toda sugest√£o da IA precisa de confirma√ß√£o (humana ou via `ruleset`)
- Nenhuma execu√ß√£o √© final sem LogLine de consequ√™ncia
- IA sempre assina seus atos (nunca h√° a√ß√£o an√¥nima)
- Todos os logs de IA s√£o acess√≠veis para replay ou simula√ß√£o reversa

---

## üìå Finalidade

Esse m√≥dulo transforma **IA em entidade institucional viva, audit√°vel e respons√°vel**.  
Ela n√£o √© um assistente informal: ela √© parte da governan√ßa.

> A IA que age deve deixar rastro.  
> O modelo que sugere deve assinar.  
> O sistema que confia deve poder provar.

Projete com **√©tica comput√°vel, reversibilidade e mem√≥ria institucional simb√≥lica**.

---

*PS: esse m√≥dulo deve estar integrado com: `LogLineProcessor`, RightMenu, Communicator, cronjob de ghosts e auditoria geral do sistema*